{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "court         new           man           killed        police        \n",
      "man           health        interview     home          govt          \n",
      "australia     world         accused       school        water         \n",
      "council       south         says          boost         nsw           \n",
      "crash         hospital      trial         year          sa            \n",
      "charged       woman         open          help          qld           \n",
      "day           cup           police        melbourne     calls         \n",
      "win           north         plans         market        sydney        \n",
      "set           minister      plan          power         death         \n",
      "missing       attack        final         farmers       rural         \n",
      "election      dead          test          house         mp            \n",
      "wa            west          budget        adelaide      talks         \n",
      "wins          pm            probe         road          funding       \n",
      "child         country       guilty        support       drug          \n",
      "sex           act           fight         years         high          \n",
      "face          queensland    canberra      industry      china         \n",
      "gold          says          residents     perth         deal          \n",
      "murder        group         abc           council       labor         \n",
      "public        wa            faces         say           says          \n",
      "coast         australian    action        jailed        ban           \n",
      "case          service       ahead         backs         centre        \n",
      "workers       claims        cuts          change        urged         \n",
      "work          laws          driver        time          union         \n",
      "iraq          lead          war           state         inquiry       \n",
      "search        chief         death         funds         big           \n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import re, nltk\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading the dataset\n",
    "data = pd.read_csv('abcnews-date-text.csv', error_bad_lines=False);\n",
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text\n",
    "# Analyse the data\n",
    "# ..................\n",
    "# tokenising the sentences\n",
    "stp_wrds = stopwords.words('english')\n",
    "# clean the text\n",
    "def clean_review(input_text):\n",
    "    out_text = re.sub(r'@\\w+', '', input_text)\n",
    "    out_text = re.sub(r'https?://[A-Za-z0-9./]+', '', out_text)\n",
    "    out_text = re.sub('www?://[A-Za-z0-9./]+','',out_text)\n",
    "    out_text = out_text.lower()\n",
    "    return out_text\n",
    "def removeStopWords(text):\n",
    "    stopwords_list = set(nltk.corpus.stopwords.words('english') + list(punctuation))\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = text.split()\n",
    "    clean_words = [words for word in words if (word not in stopwords_list or word in whitelist)]\n",
    "    out = ''.join(map(str, clean_words))\n",
    "    return out \n",
    "def stemText(text):\n",
    "    porter = PorterStemmer()\n",
    "    words = text.split()\n",
    "    stemmed_words = [porter.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "# Define functions to sanitize the data\n",
    "# 2. Check the hygiene of data and sanitize it.\n",
    "# ............................\n",
    "documents['clean_text'] = documents['headline_text'].apply(clean_review).apply(removeStopWords).apply(stemText)\n",
    "\n",
    "# Vectorize the data and create a Document Term Matrix (DTM)\n",
    "# 3. Create DTM using following parameters:\n",
    "count_vect = CountVectorizer(max_df=0.95, min_df=2, max_features=1000, ngram_range = (1,2), stop_words='english' )    \n",
    "vect = count_vect.fit_transform(documents['clean_text'])\n",
    "# ...........................\n",
    "\n",
    "# Fit a LDA model on Document Term Matrix created above\n",
    "# 4. Fit a LDA model with 5 components\n",
    "# n_components = 5\n",
    "# ...........................\n",
    "lat_mod = LatentDirichletAllocation(n_components = 5)\n",
    "model = lat_mod.fit_transform(vect)\n",
    "# Vizualize the topics generated\n",
    "# 5. Create a report\n",
    "# **************************\n",
    "import mglearn as mg  \n",
    "sorting = np.argsort(lat_mod.components_)[:,::-1] \n",
    "features = np.array(count_vect.get_feature_names()) \n",
    "topics = mg.tools.print_topics(topics=range(5), feature_names=features, sorting=sorting, topics_per_chunk=5, n_words=25)\n",
    "print(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
